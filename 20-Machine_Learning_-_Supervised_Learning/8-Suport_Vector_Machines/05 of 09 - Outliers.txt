SUPPORT VECTOR MACHINES
Outliers
SVMs try to maximize the size of the margin while still correctly separating the points of each class. As a result, outliers can be a problem. Consider the image below.

One graph with a hard margin and one graph with a soft margin
The size of the margin decreases when a single outlier is present, and as a result, the decision boundary changes as well. However, if we allowed the decision boundary to have some error, we could still use the original line.

SVMs have a parameter C that determines how much error the SVM will allow for. If C is large, then the SVM has a hard margin — it won’t allow for many misclassifications, and as a result, the margin could be fairly small. If C is too large, the model runs the risk of overfitting. It relies too heavily on the training data, including the outliers.

On the other hand, if C is small, the SVM has a soft margin. Some points might fall on the wrong side of the line, but the margin will be large. This is resistant to outliers, but if C gets too small, you run the risk of underfitting. The SVM will allow for so much error that the training data won’t be represented.

When using scikit-learn’s SVM, you can set the value of C when you create the object:

classifier = SVC(C = 0.01)
The optimal value of C will depend on your data. Don’t always maximize margin size at the expense of error. Don’t always minimize error at the expense of margin size. The best strategy is to validate your model by testing many different values for C.

Instructions
1.
Run the code to see the SVM’s current boundary line. Note that we’ve imported some helper functions we wrote named draw_points and draw_margins to help visualize the SVM.

2.
Let’s add an outlier! Before calling .fit(), append [3, 3] to points and append 0 to labels. This will add a blue point at [3, 3]


Hint
You can add [3, 3] to points by doing the following:

points.append([3, 3])
3.
Right now, our classifier has hard margins because C = 1. Change the value of C to 0.01 to see what the SVM looks like with soft margins.


Hint
When you create classifier, change the value of C to 0.01.

4.
append at least two more points to points. If you want the points to appear on the graph, make sure their x and y values are between 0 and 12.

Make sure to also append a label to labels for every point you add. A 0 will make the point blue and a 1 will make the point red.

Make sure to add the points before training the SVM.


Hint
If you wanted to add a red point at [10, 8], do the following:

points.append([10,8])
labels.append(1)
5.
Play around with the C variable to see how the decision boundary changes with your new points added. Change C to be a value between 0.01 and 1.